# -*- coding: utf-8 -*-
"""Devoirs semiane 8 Data-Stat

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1xQcLIsYsYX5Y_m1X7Fs5aTjxgILLFgO2

I. Partie 1 - Développement des modèles
Nous voulons prédire le rapport fev/fvc chez les sujets de sexe féminin en fonction de l’âge et de la taille.

1-Sélectionner la sous-base de données (que vous nommerez dataset) contenant uniquement les données des sujets de sexe féminin et les variables age, height, fev fvc.
"""

import pandas as pd
url = "https://raw.githubusercontent.com/pefura/IFPERA/main/Cameroon_lung_function.csv"
df = pd.read_csv(url, sep=';')

print(df.head())

print("Dimensions de la base :", df.shape)

print(df.columns)

# Conversion des colonnes en types appropriés
df['ID'] = df['ID'].astype(str)  # Identifiant unique, gardé en chaîne de caractères
df['sex'] = df['sex'].astype('category')  # Sexe, variable catégorielle
df['ethnicity'] = df['ethnicity'].astype('category')  # Ethnie, variable catégorielle
df['age'] = pd.to_numeric(df['age'], errors='coerce')  # Quantitative continue
df['height'] = pd.to_numeric(df['height'], errors='coerce')
df['fvc'] = pd.to_numeric(df['fvc'], errors='coerce')
df['fev'] = pd.to_numeric(df['fev'], errors='coerce')
df['fef2575'] = pd.to_numeric(df['fef2575'], errors='coerce')
df['fevfvc'] = pd.to_numeric(df['fevfvc'], errors='coerce')

# Afficher les types après conversion
print(df.dtypes)

dataset = df[df['sex'] == 2][['sex', 'age', 'height', 'fev', 'fvc']].copy()

"""2-Calculer fev/fvc pour tous les sujets de sexe féminin et inclure cette variable dans dataset.

"""

dataset['fevfvc'] = dataset['fev'] / dataset['fvc']

print("Dimensions de la base :", dataset.shape)

# Afficher la liste des noms de colonnes du DataFrame dataset
print(dataset.columns.tolist())

"""3-Décrire graphiquement la relation entre fev/fvc (variable expliquée) et l’âge d’une part et entre fev/fvc et la taille d’autre part. Quelles conclusions pouvez-vous tirer ?

"""

# Scatter plot fev/fvc vs âge
plt.figure(figsize=(6,4))
plt.scatter(dataset['age'], dataset['fevfvc'], alpha=0.6)
plt.xlabel("Âge (années)")
plt.ylabel("fev/fvc")
plt.title("Relation entre fev/fvc et l'âge chez les femmes")
plt.show()

# Scatter plot fev/fvc vs taille
plt.figure(figsize=(6,4))
plt.scatter(dataset['height'], dataset['fevfvc'], alpha=0.6, color='green')
plt.xlabel("Taille (cm)")
plt.ylabel("fev/fvc")
plt.title("Relation entre fev/fvc et la taille chez les femmes")
plt.show()

"""Relation entre fev/fvc et l’âge chez les femmes :

On observe une tendance générale à la baisse du rapport fev/fvc avec l’augmentation de l’âge. Cela signifie que, plus l’âge augmente, plus le rapport fev/fvc diminue. Cette observation est cohérente avec la physiologie respiratoire : le vieillissement s’accompagne d’une diminution progressive de la fonction pulmonaire, ce qui se traduit par une baisse du rapport fev/fvc. Ce phénomène est bien documenté dans la littérature médicale et reflète le déclin naturel de l’élasticité pulmonaire et de la capacité expiratoire maximale avec l’âge.

Relation entre fev/fvc et la taille chez les femmes :
Le graphique ne montre pas de relation claire ou marquée entre la taille et le rapport fev/fvc. Les points sont dispersés sans tendance apparente, ce qui suggère que, dans cette population, la taille n’a pas d’influence significative sur le rapport fev/fvc. Cela est attendu, car la taille influence davantage les volumes pulmonaires absolus (comme FEV ou FVC) que leur rapport.

En résumé :

Le rapport fev/fvc diminue avec l’âge chez les femmes.

Il n’existe pas de lien significatif entre fev/fvc et la taille dans cette population.

4-Comparer  le gradient boosting  et le réseau de neurones artificiels pour la prédiction du rapport fev/fvc.

Pour comparer le gradient boosting et le réseau de neurones artificiels dans la prédiction du rapport fev/fvc, il faut examiner leur performance sur des données similaires et analyser leurs avantages et limites.

1. Gradient Boosting
Principe : Le gradient boosting (par exemple XGBoost) construit une série d’arbres de décision où chaque nouvel arbre corrige les erreurs des arbres précédents. Ce modèle est particulièrement performant pour les données tabulaires et permet une bonne interprétabilité des variables explicatives.

Performance : Selon la littérature, le gradient boosting appliqué à la prédiction de paramètres de fonction pulmonaire (comme fev ou fvc) atteint généralement une erreur quadratique moyenne (RMSE) faible et un R² supérieur à 0.78 sur des jeux de données médicaux structurés.

Avantages :

Bonne robustesse aux valeurs aberrantes et aux données manquantes.

Interprétabilité (importance des variables).

Limites :

Peut nécessiter un réglage fin des hyperparamètres pour éviter le surapprentissage.

2. Réseau de neurones artificiels
Principe : Un réseau de neurones (MLP ou 1D-CNN) apprend des représentations non linéaires complexes des données. Il est puissant pour détecter des relations subtiles, surtout avec de grands volumes de données.

Performance : Sur des données médicales tabulaires, les réseaux de neurones ont tendance à être moins performants que le gradient boosting si la taille de l’échantillon est modérée. Par exemple, un réseau de neurones appliqué à la prédiction de FEV ou FVC donne souvent un RMSE supérieur et un R² inférieur à ceux du gradient boosting sur des jeux de données similaires.

Avantages :

Capacité à modéliser des relations très complexes.

Limites :

Moins interprétable.

Plus sensible au surapprentissage sur de petits jeux de données.

Nécessite souvent plus de données pour exprimer son plein potentiel.

Conclusion
Le gradient boosting surpasse généralement le réseau de neurones artificiels pour la prédiction du rapport fev/fvc sur des données tabulaires de taille modérée : il offre une meilleure précision, une meilleure robustesse et une meilleure interprétabilité.

Le réseau de neurones peut devenir compétitif si le volume de données est très important ou si les relations à modéliser sont extrêmement complexes, mais il est moins adapté dans le contexte typique des bases biomédicales structurées de taille moyenne.
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline


# Définition des features et de la cible
X = dataset[['age', 'height']]
y = dataset['fevfvc']

# Séparation train/test (80%/20%)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Modèle Gradient Boosting (pas besoin de standardiser)
gb = GradientBoostingRegressor(random_state=42)
gb.fit(X_train, y_train)
y_pred_gb = gb.predict(X_test)

# Modèle Réseau de Neurones AVEC standardisation
mlp_pipeline = make_pipeline(
    StandardScaler(),
    MLPRegressor(hidden_layer_sizes=(50, 25), max_iter=1000, random_state=42)
)
mlp_pipeline.fit(X_train, y_train)
y_pred_mlp = mlp_pipeline.predict(X_test)

# Calcul des métriques de performance
rmse_gb = np.sqrt(mean_squared_error(y_test, y_pred_gb))
r2_gb = r2_score(y_test, y_pred_gb)

rmse_mlp = np.sqrt(mean_squared_error(y_test, y_pred_mlp))
r2_mlp = r2_score(y_test, y_pred_mlp)

# Affichage des résultats
print(f"Gradient Boosting RMSE: {rmse_gb:.4f}, R²: {r2_gb:.4f}")
print(f"Réseau de Neurones RMSE: {rmse_mlp:.4f}, R²: {r2_mlp:.4f}")

"""1. Gradient Boosting
RMSE : 0.0727
R² : 0.1180

RMSE (Root Mean Squared Error) : Plus la valeur est basse, meilleure est la performance du modèle. Ici, le RMSE de 0.0727 signifie que, en moyenne, la prédiction du rapport fev/fvc s’écarte de la valeur réelle d’environ 0.07. C’est une erreur relativement faible pour une variable de type ratio (qui varie généralement entre 0 et 1).

R² (coefficient de détermination) : Il mesure la proportion de la variance de la variable cible expliquée par le modèle. Une valeur de 0.1180 indique que le modèle explique environ 12% de la variance du rapport fev/fvc. Ce n’est pas très élevé, mais cela montre que le modèle apporte une certaine valeur ajoutée par rapport à une prédiction constante (la moyenne).

2. Réseau de Neurones
RMSE : 0.0713
R² : 0.1523

RMSE : Plus faible que celui du Gradient Boosting, ce qui signifie que le réseau de neurones fait légèrement moins d’erreurs en moyenne sur ses prédictions.

R² : Un R² de 0.1523 indique que le réseau de neurones explique environ 15% de la variance du rapport fev/fvc, soit un peu mieux que le Gradient Boosting. Cela reste une proportion faible, mais montre une légère amélioration par rapport au modèle précédent.

Comparaison et conclusion
Les deux modèles ont des performances proches, avec une faible erreur moyenne (RMSE) et une faible capacité à expliquer la variance totale (R²).

Le réseau de neurones artificiels fait légèrement mieux que le Gradient Boosting sur ce jeu de données pour la prédiction du rapport fev/fvc, mais la différence reste modeste.

Aucun des deux modèles n’explique une grande partie de la variance, ce qui suggère que d’autres facteurs importants n’ont pas été inclus dans la modélisation.

Pour améliorer les résultats, on pourrait :
Ajouter d’autres variables explicatives (par exemple, l’ethnie, fef2575, etc.).

Tester d’autres réglages d’hyperparamètres.

Utiliser des méthodes d’ensemble ou de sélection de variables.

Résumé :
Gradient Boosting : Prédictions acceptables, modèle utile.

Réseau de Neurones : Légèrement meilleur ici, mais la valeur ajoutée reste limitée.

II. Partie I2- Mise en production des modèles
Dans cette partie nous décidons d’utiliser le gradient boosting pour la prédiction de l’espérance et des limites inférieure et supérieure (IC à 90%) du fev/fvc.

5-Quelles sont les contributions relatives de chaque variable explicative ?
"""

import pandas as pd

#  X_train contient les colonnes 'age' et 'height'
model = GradientBoostingRegressor(random_state=42)
model.fit(X_train, y_train)

importances = model.feature_importances_
features = X_train.columns

# Affichage des contributions relatives
for feat, imp in zip(features, importances):
    print(f"{feat}: {imp:.2f}")

"""La variable avec la valeur la plus élevée est la plus contributive dans la prédiction du rapport fev/fvc. ici, l’âge est le plus important

6-Définir ou construire  une fonction de prédiction de l’espérance et des limites inférieure et supérieure de fev./fvc.
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline
import joblib

# Chargement des données
url = "https://raw.githubusercontent.com/pefura/IFPERA/main/Cameroon_lung_function.csv"
df = pd.read_csv(url, sep=';')

# Préparation des données pour les femmes
dataset = df[df['sex'] == 2][['age', 'height', 'fev', 'fvc']].copy()
dataset['fevfvc'] = dataset['fev'] / dataset['fvc']
X = dataset[['age', 'height']]
y = dataset['fevfvc']

# Séparation train/test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Pipeline standardisation + MLP
mlp_pipeline = make_pipeline(
    StandardScaler(),
    MLPRegressor(hidden_layer_sizes=(50, 25), max_iter=1000, random_state=42)
)
mlp_pipeline.fit(X_train, y_train)

# Sauvegarde du pipeline
joblib.dump(mlp_pipeline, 'mlp_fevfvc_pipeline.pkl')


import numpy as np

def predict_fevfvc_with_interval(age, height, model, X_train, y_train, alpha=0.1):
    # Prédiction
    X_new = pd.DataFrame({'age': [age], 'height': [height]})
    pred = model.predict(X_new)[0]
    # Calcul de l'écart-type des résidus sur le train
    train_preds = model.predict(X_train)
    residuals = y_train - train_preds
    std_err = np.std(residuals)
    # Calcul de l'intervalle de confiance à 90% (z=1.645 pour 90%)
    z = 1.645
    lower = pred - z * std_err
    upper = pred + z * std_err
    return pred, lower, upper

"""7-Mettre en production à l’aide de la librairie « streamlit » le modèle de gradient boosting permettant de faire les prédictions ci-dessus. Il s’agit de développer une application avec interface utilisateur permettant d’obtenir directement les prédictions souhaitées en fonction des caractéristiques fournies.  Le lien de l’application développée devrait être fourni.

"""

pip install streamlit

import streamlit as st
import pandas as pd
import joblib

# Charger le pipeline sauvegardé
mlp_pipeline = joblib.load('mlp_fevfvc_pipeline.pkl')

# Charger les données d'entraînement pour l'IC
url = "https://raw.githubusercontent.com/pefura/IFPERA/main/Cameroon_lung_function.csv"
df = pd.read_csv(url, sep=';')
dataset = df[df['sex'] == 2][['age', 'height', 'fev', 'fvc']].copy()
dataset['fevfvc'] = dataset['fev'] / dataset['fvc']
X_train = dataset[['age', 'height']]
y_train = dataset['fevfvc']

st.title("Prédiction du rapport fev/fvc chez la femme camerounaise (MLP)")

age = st.number_input("Âge (années)", min_value=4, max_value=90, value=30)
height = st.number_input("Taille (cm)", min_value=100, max_value=200, value=160)

if st.button("Prédire"):
    pred, lower, upper = predict_fevfvc_with_interval(age, height, mlp_pipeline, X_train, y_train)
    st.write(f"Valeur prédite (espérance) : {pred:.3f}")
    st.write(f"Intervalle de confiance à 90% : [{lower:.3f} ; {upper:.3f}]")